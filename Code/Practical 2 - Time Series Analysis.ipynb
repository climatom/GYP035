{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis with Python/Pandas\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "In this session we're going to move swiftly on from our generic introduction to programming covered last time. By the end of the session, we will have used python to do something genuinely useful -- we will generate a 'day of year climatology' for air temperature at the Loughborough weather station. As discussed, this can be employed as a type of prediction, and we will use it as such to forecast temperatures between now and the next session. Later in the course we will then see if this performance can be improved upon using more sophisticated methods to capture variability arount the climatology (i.e. the 'weather'!) \n",
    "\n",
    "To achieve the aim indicated above, we will make use of python $\\it{modules}$. These are libraries of code -- written by others -- which we can use to do sophisticated analysis. Use of modules speeds up our work by several orders of magnitude, and enables us to build on the collective skill of tens of thousands of programmers. \n",
    "\n",
    "Today, we will mainly be using the \"pandas\" module, which was created with data scientists in mind. Pandas enables us to use syntax that is far more intuitive than often encountered elsewhere, and it comes loaded with lots of super-helpful functions. We will only scratch the surface of pandas today, but will return to it in later sessions. \n",
    "\n",
    "We load the pandas module like this (note: please run code like this as you move through the notebook): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the generic syntax -- \"import x as y\". This means, basically, 'load' the module x, but let me refer to it as y. We do this because we will access attributes of the module using its name and the \".\" notation, and it is laborious (and prone to error) if we have to type out the full name of the moudle each time we want to access one of its attributes -- so we use shorthand wherever possible. \n",
    "\n",
    "We are also going to import some other modules needed for today's session: \n",
    "\n",
    "- Matplotlib (https://matplotlib.org/) -- used for making plots/graphs\n",
    "- Numpy (https://numpy.org/) -- used for numerical computation in python\n",
    "- Sklearn (https://scikit-learn.org/stable/) -- used for 'machine learning'\n",
    "\n",
    "Of these, matplotlib and numpy are modules you will use exceptionally often if continuing to learn python after this course. Sklearn brings the dark art of \"machine learning\" -- an application of \"artifical intelligence\" -- to python. We will use if for something far more mundane/familiar today! \n",
    "\n",
    "Run the code below to load the modules. Also note that I have defined a function for you in here (called 'seas_cycle') -- it uses methods from the numpy and sklearn to help 'model' the seasonal cycle of a variable (like air temperature). You will use this later, but don't need to understand all the individual bits of code now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4429deb57db5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinear_model\u001b[0m \u001b[1;31m# this is a little different again,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# I'm only importing one attribute (linear_model) from sklearn.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# --------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# These are the 'import' statements\n",
    "# --------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt # note that here I do something subtly \n",
    "# different - I import an attribute of matplotlib -- called 'pyplot'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model # this is a little different again, \n",
    "# I'm only importing one attribute (linear_model) from sklearn. \n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# Below is the code where I define a function for us to use. You do not need\n",
    "# to understand this yet.\n",
    "# --------------------------------------------------------------------------\n",
    "def seas_cycle(ind,n,indata):\n",
    "    y=indata.values[:]\n",
    "    reg = linear_model.LinearRegression() \n",
    "    ind = 2*np.pi*(ind/np.float(n)) \n",
    "    idx = ~np.isnan(y)\n",
    "    X = np.column_stack((np.cos(ind[idx]),np.sin(ind[idx])))\n",
    "    reg.fit(X, y[idx]) \n",
    "    sim = reg.predict(np.column_stack((np.cos(ind),np.sin(ind)))) \n",
    "    return sim\n",
    "# --------------------------------------------------------------------------    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best way to illustrate the power of Pandas is then by example -- as we work towards our goal of computing a \"climatology\" to make some predictions about the weather. Let's begin by loading data from our very own campus weather stations introduced to you already. You will need to change the path (i.e. the variable 'fin') for this code to work for you -- it will need to reflect where you stored the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin=\"C:/Users/gytm3/OneDrive - Loughborough University/Teaching/GYP035/201920/Campus_Met_Data_Student.csv\"\n",
    "date_parser=lambda x: pd.datetime.strptime(x,'%Y-%m-%d %H:%M:%S')\n",
    "data=pd.read_csv(fin,parse_dates=[\"TIMESTAMP\"],date_parser=date_parser,index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be clear, I'm accessing the 'method' (or 'function') 'read_csv' that is part of the pandas module. The 'arguments' or 'parameters' I provide to the function are those comma-separated items within the brackets: the first is the $\\it{full}$ filename, the second is a flag that tells pandas that it should try to interpret any dates in the file; and the third is an instruction to tell pandas that the first column of data in the file should be used to index the data -- i.e. which column is the 'axis'. The result of this command is the creation of a new variable called 'data', which is a 'DataFrame' -- a specific type that is available in the pandas module. DataFrames are very clever data types, ideally set up for data analysis. You will see some of these features as we progress through the session. \n",
    "\n",
    "How would $\\it{you}$ figure out what arguments are needed by this method if you didn't have me here to tell you? Easy, you search the help pages. In this case, googling the 'read_csv' method of the pandas module should take you to this page: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html. Or, alternatively, you can ask python directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personally, I prefer reading in my browser...\n",
    "\n",
    "OK. So back to why we should get excited about pandas and DataFrames...  Below we're goint to print an attribute of data -- 'columns'. This simply outputs a list -- which corresponds to the headings in our csv file. We do this because it's a good check that the data have been read correctly -- and to make sure we refer to the different variables in a way that pandas will understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the above should confirm that pandas has understood the structure of your input data. Now, let's immediately do something fun. Let's make a plot of air temperature (which we see is called 'AirTC_Avg'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This first command is needed to make the plots 'appear' in this notebook\n",
    "%matplotlib inline \n",
    "data[\"AirTC_Avg\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How easy was that? And look - pandas has recognised that date (labelled as 'TIMESTAMP') should be used as the x-axis! Ha! Take that, Microsoft Excel, and your habit of ruining my life with your trouble processing dates... \n",
    "\n",
    "It's important to digest what we have just done: \n",
    "\n",
    "- indexing: data[\"AirTC_Avg\"] is another, far more intuitive way of 'indexing' an 'iterable' (covered last session) that pandas enables us to use on the DataFrame type  \n",
    "- plotting: the .plot() call is us using the plot method of the data[\"AirTC_Avg\"] variable. There are other ways to make plots in python, but none as straightforward for us -- be glad when your data are in a pandas DataFrame!\n",
    "\n",
    "OK, so that might not seem too impressive; let's do something else to showcase what pandas can do -- and make something more informative to plot at the same time.\n",
    "\n",
    "Below I'm going to use the 'resample' method to, as you may guess, sub-select (or sample) the data. The resample I'm going to perform is to move from 15-min data (the native format), to daily resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_t=data[\"AirTC_Avg\"].resample(\"D\") # Note that the \"D\" indiates \"Daily\".\n",
    "# Even though the code will be new to you, hopefully you find it relatively \n",
    "# intuitive. This readability is a deliberate feature of python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing happened! \n",
    "\n",
    "That's right. All that pandas has done is some work behind the scenes to aggregate the data into daily chunks. But $\\it{how}$ do we want to summarise the data at this lower (daily) resolution -- where we move from 24 x 4 = 96 values/day to just 1? \n",
    "\n",
    "Well, we can choose, by applying another method to the resampler ('daily_t' is the resampler). Below we compute daily mean, min, and max temperatures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "daymean_t=daily_t.mean()\n",
    "daymax_t=daily_t.max()\n",
    "daymin_t=daily_t.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that above I call a method with the parentheses, but there are no arguments included. This is beacause pandas does not need any more information to calculate the mean, max or min -- just the variable itself (in this case, daily_t). \n",
    "\n",
    "daymean_t, daymax_t, and daymin_t are now stand-alone variables containing the daily mean, maximum, and minimum temperature, respectively. To check this, we can plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daymean_t.plot()\n",
    "daymax_t.plot()\n",
    "daymin_t.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad, eh? And look how hot it was this summer! Let's ask pandas to tell us what this 'record' temperature was..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Record high temperature was: \",daymax_t.max(),\"deg C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And how about the min?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Record low temperature was: \",daymin_t.min(),\"deg C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above plots, you can, I hope, clearly make out the cyclical nature of the temperatures, with four 'peaks' (summers) and three 'troughs' (winters).  \n",
    "\n",
    "There are a few ways we can 'model' this behaviour to produde a 'day of year climatology' (hereafter 'DoY climatology'). One of the easiest is to group together all the 'days of the year' and average them. For example, we could find all the January 1sts (there will be 3 of them), and find the average value -- repeating for Jan 2nd, and so forth). The code for this is a bit clunky (or at least, has quite a bit going on that you may not understand), but execute the below to generate a DoY climatology -- using mean temperatures for our example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doy=daymean_t.index.dayofyear # finds the DoY from the date/time axis\n",
    "doy_clim=daymean_t.groupby(doy).mean() # ** finds mean value for the all those unique DoYs\n",
    "# line below puts the correct DoY mean value at the right date\n",
    "doy_mean=[doy_clim[doy_clim.index==i].values[0] for i in doy.values[:]] # "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we look at the output of that, let's estimate the DoY climatology another way -- using a sine wave to approximate the smooth undulation. For those of you unfamiliar with a sine wave, here's the world's briefiest overview of what it is:\n",
    "\n",
    "... A sine wave is the curve that is produced by taking the \"sine\" of an ordered sequence of angles between 0 and 360 degrees (or 2$\\pi$ radians). The \"sine\" of argument $x$, remember, is just the ratio of the 'opposite' (vertical) to 'hypotenuse' sides in a right angle triangle, when the angle between the hypotenuse and adjacent sides of the triangle is equal to $x$...\n",
    "\n",
    "This isn't a trigonmetry lesson, so don't worry if you've forgotten what the sine function does, and you don't understand my explanation above. We can instead just think of a sine wave as a function that creates a periodic (repeating), smooth 'wave' form. As discussed in the lecture, there is good physical reason why we expect that this particular shape should describe our temperature data well.\n",
    "\n",
    "In the below, I demonstrate a sine wave, creating a sequence of numbers to represent the angles 0-360 (using the 'arange' method of numpy); I then feed this to the sine method of numpy (called 'sin') and plot the result for you to see what it looks like. Don't be confused by the 'radians' command -- this just converts the angles into the form that numpy expects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles=np.radians(np.arange(0,361)) # creates the reference series\n",
    "y=np.sin(angles) # use the sin function\n",
    "plt.plot(y) # this is another way to plot something when it isn't a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice shape, right? This has the smooth undulations just as we wanted them. However, how do we get the 'height' (amplitude) to be correct, and how do we make sure that the peak is positioned in summer and the trough in winter (i.e. that the wave has the correct 'phase'? These are important questions, but beyond the scope of our session, so I have written a function for you (the 'seas_cycle' function) to do this. Essentially, it tries to make the curve fit *all* of the data as closely as possible -- i.e passing as closely as possible to all observed temperatures. \n",
    "\n",
    "Run the code below to generate a DoY climatology using this function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clim=seas_cycle(doy.astype(np.float),365.25,daymean_t) # **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. So we are now in a position to visually compare doy_mean (the simple averaging) and clim (the sine wave) to the observations. In the code below we will create a new pandas DataFrame, inserting the observations and both models, before making a plot using the convenient .plot() method of a DataFrame. Note that here I do plot a little differently this time -- creating a blank figure and pair of axes and then plotting on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=pd.DataFrame(data={\"obs\":daymean_t.values[:],\"doy_mean\":doy_mean,\"clim\":clim},\\\n",
    "                 index=daymean_t.index) # ** creating a DataFrame\n",
    "fig,ax=plt.subplots(1,1) # blank figure/axes to plot on\n",
    "out.plot(ax=ax) # normal call to plot -- but specifying 'ax' to plot on\n",
    "ax.set_ylabel(\"Air temperature (deg C)\") # cosmetics -- label y-axis\n",
    "ax.set_xlabel(\"Date\") # cosmetics -- label x-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now save the DataFrame 'out' to a .csv file (which can be opened in Excel -- and read back in using python). We will do this so that you can explore the data outside of the notebook -- and so that you can easily build on this dataset in the future. Change 'fout' in the code below (to indicate the path of the file you want to save the data in), and then execute the code block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fout=\"C:/Users/gytm3/OneDrive - Loughborough University/Teaching/GYP035/201920/DoY_climatology_tmean.csv\" # **\n",
    "out.to_csv(fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your challenge -- to be completed before the next practical\n",
    "\n",
    "- Edit the code segments above so that you repeat the modelling for the daily min and daily maximum temperatures. [Hint: this is not as tricky as it seems -- look for bits of code with # ** -- these are the only bits you need to edit]\n",
    "\n",
    "\n",
    "- Use the output (.csv files) to estimate:\n",
    "\n",
    "\n",
    "    - the date most likely to record the annual maximum temperature \n",
    "    - the date most likely to record the annual minimum temperature\n",
    "    - the mean temperature on the day of our next practical (Monday)\n",
    "    \n",
    "\n",
    "- Finally, which method (doy_mean or clim) do you think does a 'better' job of capturing the observed air temperature variability? Suggest ways in which we could 'score' the different methods. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
